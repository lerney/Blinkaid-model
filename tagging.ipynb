{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672de1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Blinking.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\Blinking.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\Blinking_prcsd.csv\n",
      "Processing file: blinks.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\blinks.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\blinks_prcsd.csv\n",
      "Processing file: eye gaze left right 1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\eye gaze left right 1.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\eye gaze left right 1_prcsd.csv\n",
      "Processing file: eye gaze left right 2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\eye gaze left right 2.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\eye gaze left right 2_prcsd.csv\n",
      "Processing file: Eye Gazing.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\Eye Gazing.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\Eye Gazing_prcsd.csv\n",
      "Processing file: eye movements up down.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\eye movements up down.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\eye movements up down_prcsd.csv\n",
      "Processing file: noise.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\noise.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\noise_prcsd.csv\n",
      "Processing file: raise eybrows quick + garbage.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\raise eybrows quick + garbage.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\raise eybrows quick + garbage_prcsd.csv\n",
      "Processing file: raise eyebrows and hold.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\raise eyebrows and hold.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\raise eyebrows and hold_prcsd.csv\n",
      "Processing file: reading outloud.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\reading outloud.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\reading outloud_prcsd.csv\n",
      "Processing file: reading.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\reading.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\reading_prcsd.csv\n",
      "Processing file: smiling.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\smiling.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\smiling_prcsd.csv\n",
      "Processing file: squinting.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9764\\2940257937.py:27: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\squinting.csv → C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\\squinting_prcsd.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def transform_emg_data(input_csv, output_csv):\n",
    "    \"\"\"Transforms a CSV file by reformatting timestamps to ISO 8601 format with milliseconds.\"\"\"\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Extract column names (excluding timestamp)\n",
    "    channels = df.columns[1:]\n",
    "\n",
    "    # Prepare an empty list for the transformed data\n",
    "    transformed_data = []\n",
    "\n",
    "    # Define possible timestamp formats\n",
    "    timestamp_formats = [\n",
    "        \"%d/%m/%Y %H:%M:%S.%f\",  # 19/12/2023 00:17:57.870000\n",
    "        \"%d/%m/%Y %H:%M:%S\",     # 19/12/2023 00:17:57\n",
    "        \"%d/%m/%Y %H:%M\",        # 19/12/2023 00:17\n",
    "        \"%Y-%m-%d %H:%M:%S.%f\",  # 2023-12-19 00:17:57.870000\n",
    "        \"%Y-%m-%d %H:%M:%S\",     # 2023-12-19 00:17:57\n",
    "        \"%Y-%m-%d %H:%M\"         # 2023-12-19 00:17\n",
    "    ]\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "        timestamp_str = str(row[0]).strip()  # Ensure timestamp is a string and remove any spaces\n",
    "\n",
    "        parsed_time = None\n",
    "        for fmt in timestamp_formats:\n",
    "            try:\n",
    "                parsed_time = datetime.strptime(timestamp_str, fmt)\n",
    "                break\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        if parsed_time is None:\n",
    "            print(f\"Skipping row {row_idx}: Unrecognized timestamp format → {timestamp_str}\")\n",
    "            continue  # Skip problematic rows\n",
    "\n",
    "        # Convert timestamp to ISO 8601 format with milliseconds\n",
    "        formatted_time = parsed_time.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
    "\n",
    "        # Iterate through each channel\n",
    "        for channel in channels:\n",
    "            transformed_data.append([channel, formatted_time, row[channel], \"\"])  # Empty label\n",
    "\n",
    "    # Create a new DataFrame\n",
    "    transformed_df = pd.DataFrame(transformed_data, columns=[\"series\", \"timestamp\", \"value\", \"label\"])\n",
    "\n",
    "    # Save the transformed data\n",
    "    transformed_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Processed: {input_csv} → {output_csv}\")\n",
    "\n",
    "def process_all_csv_files(input_folder, output_folder):\n",
    "    \"\"\"Processes all CSV files in input_folder and saves them in output_folder.\"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)  # Ensure output folder exists\n",
    "\n",
    "    # Loop through all CSV files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".csv\"):  # Process only CSV files\n",
    "            input_csv = os.path.join(input_folder, filename)\n",
    "            output_csv = os.path.join(output_folder, filename.replace(\".csv\", \"_prcsd.csv\"))\n",
    "            \n",
    "            print(f\"Processing file: {filename}\")\n",
    "            transform_emg_data(input_csv, output_csv)\n",
    "\n",
    "# Folder paths\n",
    "input_folder = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\"\n",
    "output_folder = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\processed_data\"\n",
    "\n",
    "# Process all CSV files in the folder\n",
    "process_all_csv_files(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_long_to_wide(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Converts a long-format CSV file back to wide format with labels applied across all channels.\n",
    "    \n",
    "    Parameters:\n",
    "        input_csv (str): Path to the processed labeled CSV file.\n",
    "        output_csv (str): Path to save the reconstructed wide-format CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the processed labeled CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Pivot the data back to wide format (timestamps as rows, channels as columns)\n",
    "    df_wide = df.pivot(index=\"timestamp\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # Extract labels only from 'channel_1' and apply to all rows with the same timestamp\n",
    "    df_labels = df[df[\"series\"] == \"channel_1\"][[\"timestamp\", \"label\"]]\n",
    "\n",
    "    # Merge labels back into the wide-format dataframe\n",
    "    df_wide = df_wide.merge(df_labels, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "    # Manually define correct column order (channel_1, channel_2, ..., channel_16, label)\n",
    "    channel_order = [f\"channel_{i}\" for i in range(1, 17)]  # Assuming 16 channels\n",
    "    column_order = [\"timestamp\"] + channel_order + [\"label\"]\n",
    "\n",
    "    # Reorder the columns manually\n",
    "    df_wide = df_wide[column_order]\n",
    "\n",
    "    # Save to CSV (keeping original channel names)\n",
    "    df_wide.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Transformation complete. Output saved to {output_csv}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\before_format\\eye gaze left right 1_prcsd-labeled.csv\"\n",
    "    output_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\after_format\\eye gaze left right 1_labeled_af.csv\"\n",
    "    \n",
    "    convert_long_to_wide(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8830472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. Output saved to C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\after_format\\eye movements up down-labeled-af.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_long_to_wide(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Converts a long-format CSV file back to wide format with labels applied across all channels.\n",
    "    Handles duplicate (timestamp, series) pairs by averaging values.\n",
    "\n",
    "    Parameters:\n",
    "        input_csv (str): Path to the processed labeled CSV file.\n",
    "        output_csv (str): Path to save the reconstructed wide-format CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the processed labeled CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Remove duplicates by averaging duplicate values per (timestamp, series)\n",
    "    #df = df.groupby([\"timestamp\", \"series\"], as_index=False).agg({\"value\": \"mean\", \"label\": \"first\"})\n",
    "\n",
    "    # Pivot the data back to wide format (timestamps as rows, channels as columns)\n",
    "    df_wide = df.pivot(index=\"timestamp\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # Extract labels only from 'channel_2' and apply to all rows with the same timestamp\n",
    "    df_labels = df[df[\"series\"] == \"channel_8\"][[\"timestamp\", \"label\"]]\n",
    "\n",
    "    # Merge labels back into the wide-format dataframe\n",
    "    df_wide = df_wide.merge(df_labels, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "    # Manually define correct column order (ensuring channels are ordered numerically)\n",
    "    channel_order = sorted([col for col in df_wide.columns if col.startswith(\"channel_\")], key=lambda x: int(x.split(\"_\")[1]))\n",
    "    column_order = [\"timestamp\"] + channel_order + [\"label\"]\n",
    "\n",
    "    # Reorder the columns manually\n",
    "    df_wide = df_wide[column_order]\n",
    "\n",
    "    # Save to CSV (keeping original channel names)\n",
    "    df_wide.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Transformation complete. Output saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\before_format\\eye movements up down_prcsd-labeled.csv\"\n",
    "    output_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\after_format\\eye movements up down-labeled-af.csv\"\n",
    "    convert_long_to_wide(input_csv, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3cbf7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_956\\2007049177.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(input_csv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicate (timestamp, series) pairs before processing: 61696\n",
      "Duplicate (timestamp, series) pairs after cut: 0\n",
      "Transformation complete. Output saved to C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\after_format\\raise eybrows quick + garbage_labeled_af.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def convert_long_to_wide(input_csv, output_csv):\n",
    "    \"\"\"\n",
    "    Converts a long-format CSV file back to wide format with labels applied across all channels.\n",
    "    Handles duplicate (timestamp, series) pairs by averaging values and trims dataset after last labeled timestamp.\n",
    "    Also counts duplicates before and after the cut.\n",
    "\n",
    "    Parameters:\n",
    "        input_csv (str): Path to the processed labeled CSV file.\n",
    "        output_csv (str): Path to save the reconstructed wide-format CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the processed labeled CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Count total duplicate (timestamp, series) pairs before processing\n",
    "    total_duplicates = df.duplicated(subset=[\"timestamp\", \"series\"], keep=False).sum()\n",
    "    print(f\"Total duplicate (timestamp, series) pairs before processing: {total_duplicates}\")\n",
    "\n",
    "    # Remove duplicates by averaging duplicate values per (timestamp, series)\n",
    "    df = df.groupby([\"timestamp\", \"series\"], as_index=False).agg({\"value\": \"mean\", \"label\": \"first\"})\n",
    "\n",
    "    # Pivot the data back to wide format (timestamps as rows, channels as columns)\n",
    "    df_wide = df.pivot(index=\"timestamp\", columns=\"series\", values=\"value\").reset_index()\n",
    "\n",
    "    # Extract labels only from 'channel_1' and apply to all rows with the same timestamp\n",
    "    df_labels = df[df[\"series\"] == \"channel_1\"][[\"timestamp\", \"label\"]]\n",
    "\n",
    "    # Merge labels back into the wide-format dataframe\n",
    "    df_wide = df_wide.merge(df_labels, on=\"timestamp\", how=\"left\")\n",
    "\n",
    "    # Manually define correct column order (ensuring channels are ordered numerically)\n",
    "    channel_order = sorted([col for col in df_wide.columns if col.startswith(\"channel_\")], key=lambda x: int(x.split(\"_\")[1]))\n",
    "    column_order = [\"timestamp\"] + channel_order + [\"label\"]\n",
    "\n",
    "    # Reorder the columns manually\n",
    "    df_wide = df_wide[column_order]\n",
    "\n",
    "    # Trim dataset after the last timestamp that contains a label\n",
    "    last_labeled_timestamp = df_wide[df_wide[\"label\"].notna()][\"timestamp\"].max()\n",
    "    df_wide = df_wide[df_wide[\"timestamp\"] <= last_labeled_timestamp]\n",
    "\n",
    "    # Count duplicate (timestamp, series) pairs after trimming\n",
    "    duplicates_after_cut = df_wide.duplicated(subset=[\"timestamp\"], keep=False).sum()\n",
    "    print(f\"Duplicate (timestamp, series) pairs after cut: {duplicates_after_cut}\")\n",
    "\n",
    "    # Save to CSV (keeping original channel names)\n",
    "    df_wide.to_csv(output_csv, index=False)\n",
    "\n",
    "    print(f\"Transformation complete. Output saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\before_format\\raise eybrows quick + garbage_prcsd-labeled.csv\"\n",
    "    output_csv = r\"C:\\Users\\user\\OneDrive - post.bgu.ac.il\\פרויקט Blinkaid\\data from subject1 - Yonathan\\tagged_data\\after_format\\raise eybrows quick + garbage_labeled_af.csv\"\n",
    "    \n",
    "    convert_long_to_wide(input_csv, output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
